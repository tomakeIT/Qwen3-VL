  0%|                                                      | 0/6000 [00:00<?, ?it/s]/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
                                                                                    
{'loss': 2.4012, 'grad_norm': 22.95238494873047, 'learning_rate': 0.0, 'epoch': 0.33}
{'loss': 3.7962, 'grad_norm': 56.380435943603516, 'learning_rate': 1.111111111111111e-09, 'epoch': 0.67}
{'loss': 4.5604, 'grad_norm': 90.12101745605469, 'learning_rate': 2.222222222222222e-09, 'epoch': 1.0}
{'loss': 4.5604, 'grad_norm': 91.80226135253906, 'learning_rate': 3.333333333333333e-09, 'epoch': 1.33}
{'loss': 2.4147, 'grad_norm': 23.009044647216797, 'learning_rate': 4.444444444444444e-09, 'epoch': 1.67}
{'loss': 3.7961, 'grad_norm': 57.24367141723633, 'learning_rate': 5.555555555555555e-09, 'epoch': 2.0}
{'loss': 4.6441, 'grad_norm': 91.33025360107422, 'learning_rate': 6.666666666666666e-09, 'epoch': 2.33}
{'loss': 3.7594, 'grad_norm': 56.54767990112305, 'learning_rate': 7.777777777777777e-09, 'epoch': 2.67}
{'loss': 2.4097, 'grad_norm': 23.12484359741211, 'learning_rate': 8.888888888888889e-09, 'epoch': 3.0}
{'loss': 3.8796, 'grad_norm': 54.65731430053711, 'learning_rate': 1e-08, 'epoch': 3.33}
{'loss': 4.5611, 'grad_norm': 91.40738677978516, 'learning_rate': 1.111111111111111e-08, 'epoch': 3.67}
{'loss': 2.4329, 'grad_norm': 22.847684860229492, 'learning_rate': 1.2222222222222222e-08, 'epoch': 4.0}
{'loss': 2.443, 'grad_norm': 23.21984100341797, 'learning_rate': 1.3333333333333332e-08, 'epoch': 4.33}
{'loss': 3.7889, 'grad_norm': 54.89492416381836, 'learning_rate': 1.4444444444444442e-08, 'epoch': 4.67}
{'loss': 4.6028, 'grad_norm': 91.97695922851562, 'learning_rate': 1.5555555555555554e-08, 'epoch': 5.0}
{'loss': 4.441, 'grad_norm': 90.47696685791016, 'learning_rate': 1.6666666666666664e-08, 'epoch': 5.33}
{'loss': 2.4123, 'grad_norm': 22.617258071899414, 'learning_rate': 1.7777777777777777e-08, 'epoch': 5.67}
{'loss': 3.8791, 'grad_norm': 54.93390655517578, 'learning_rate': 1.8888888888888887e-08, 'epoch': 6.0}
{'loss': 3.8428, 'grad_norm': 57.65027618408203, 'learning_rate': 2e-08, 'epoch': 6.33}
{'loss': 2.4219, 'grad_norm': 23.022289276123047, 'learning_rate': 2.111111111111111e-08, 'epoch': 6.67}
{'loss': 4.7271, 'grad_norm': 91.68525695800781, 'learning_rate': 2.222222222222222e-08, 'epoch': 7.0}
{'loss': 3.805, 'grad_norm': 56.55118942260742, 'learning_rate': 2.3333333333333334e-08, 'epoch': 7.33}
{'loss': 2.4458, 'grad_norm': 22.986902236938477, 'learning_rate': 2.4444444444444444e-08, 'epoch': 7.67}
{'loss': 4.4822, 'grad_norm': 90.90286254882812, 'learning_rate': 2.5555555555555554e-08, 'epoch': 8.0}
{'loss': 4.6485, 'grad_norm': 92.40677642822266, 'learning_rate': 2.6666666666666664e-08, 'epoch': 8.33}
{'loss': 2.4152, 'grad_norm': 23.26358985900879, 'learning_rate': 2.7777777777777777e-08, 'epoch': 8.67}
{'loss': 3.8013, 'grad_norm': 55.65329360961914, 'learning_rate': 2.8888888888888884e-08, 'epoch': 9.0}
{'loss': 4.6902, 'grad_norm': 91.61188507080078, 'learning_rate': 3e-08, 'epoch': 9.33}
{'loss': 3.8022, 'grad_norm': 56.41150665283203, 'learning_rate': 3.111111111111111e-08, 'epoch': 9.67}
{'loss': 2.4456, 'grad_norm': 23.227861404418945, 'learning_rate': 3.2222222222222224e-08, 'epoch': 10.0}
{'loss': 2.4203, 'grad_norm': 22.592601776123047, 'learning_rate': 3.333333333333333e-08, 'epoch': 10.33}
{'loss': 4.6028, 'grad_norm': 90.9076156616211, 'learning_rate': 3.4444444444444444e-08, 'epoch': 10.67}
{'loss': 3.756, 'grad_norm': 55.610206604003906, 'learning_rate': 3.5555555555555554e-08, 'epoch': 11.0}
{'loss': 3.8745, 'grad_norm': 55.58580017089844, 'learning_rate': 3.6666666666666664e-08, 'epoch': 11.33}
{'loss': 2.4354, 'grad_norm': 22.963014602661133, 'learning_rate': 3.7777777777777774e-08, 'epoch': 11.67}
{'loss': 4.5243, 'grad_norm': 92.03189086914062, 'learning_rate': 3.888888888888889e-08, 'epoch': 12.0}
{'loss': 4.7274, 'grad_norm': 91.60519409179688, 'learning_rate': 4e-08, 'epoch': 12.33}
{'loss': 3.8855, 'grad_norm': 55.606773376464844, 'learning_rate': 4.1111111111111104e-08, 'epoch': 12.67}
{'loss': 2.4354, 'grad_norm': 22.873048782348633, 'learning_rate': 4.222222222222222e-08, 'epoch': 13.0}
{'loss': 4.7694, 'grad_norm': 90.82157135009766, 'learning_rate': 4.333333333333333e-08, 'epoch': 13.33}
{'loss': 2.4274, 'grad_norm': 23.14558982849121, 'learning_rate': 4.444444444444444e-08, 'epoch': 13.67}
{'loss': 3.8479, 'grad_norm': 55.57086181640625, 'learning_rate': 4.555555555555555e-08, 'epoch': 14.0}
{'loss': 2.4049, 'grad_norm': 22.422542572021484, 'learning_rate': 4.666666666666667e-08, 'epoch': 14.33}
{'loss': 4.7274, 'grad_norm': 89.85909271240234, 'learning_rate': 4.777777777777778e-08, 'epoch': 14.67}
{'loss': 3.8381, 'grad_norm': 56.80386734008789, 'learning_rate': 4.888888888888889e-08, 'epoch': 15.0}
{'loss': 4.5194, 'grad_norm': 89.63687896728516, 'learning_rate': 5e-08, 'epoch': 15.33}
{'loss': 2.4274, 'grad_norm': 23.15775489807129, 'learning_rate': 5.111111111111111e-08, 'epoch': 15.67}
{'loss': 3.7966, 'grad_norm': 55.951263427734375, 'learning_rate': 5.2222222222222224e-08, 'epoch': 16.0}
{'loss': 2.4362, 'grad_norm': 22.732126235961914, 'learning_rate': 5.333333333333333e-08, 'epoch': 16.33}
{'loss': 4.6441, 'grad_norm': 92.15446472167969, 'learning_rate': 5.444444444444444e-08, 'epoch': 16.67}
{'loss': 3.7621, 'grad_norm': 55.32422637939453, 'learning_rate': 5.5555555555555555e-08, 'epoch': 17.0}
{'loss': 3.7894, 'grad_norm': 56.54492950439453, 'learning_rate': 5.6666666666666665e-08, 'epoch': 17.33}
{'loss': 4.6028, 'grad_norm': 92.11992645263672, 'learning_rate': 5.777777777777777e-08, 'epoch': 17.67}
{'loss': 2.4124, 'grad_norm': 22.907556533813477, 'learning_rate': 5.888888888888889e-08, 'epoch': 18.0}
  File "/home/erdao/Documents/Qwen3-VL/qwen-vl-finetune/qwenvl/train/train_qwen.py", line 206, in <module>
    train(attn_implementation="flash_attention_2")
  File "/home/erdao/Documents/Qwen3-VL/qwen-vl-finetune/qwenvl/train/train_qwen.py", line 195, in train
    trainer.train()
  File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
  File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/transformers/trainer.py", line 2618, in _inner_training_loop
    batch_samples, num_items_in_batch = self.get_batch_samples(epoch_iterator, num_batches, args.device)
  File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/transformers/trainer.py", line 5654, in get_batch_samples
    batch_samples.append(next(epoch_iterator))
  File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/accelerate/data_loader.py", line 563, in __iter__
    dataloader_iter = self.base_dataloader.__iter__()
  File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 491, in __iter__
    return self._get_iterator()
  File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 422, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1146, in __init__
    w.start()
  File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/multiprocessing/context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/multiprocessing/context.py", line 288, in _Popen
    return Popen(process_obj)
  File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/multiprocessing/popen_spawn_posix.py", line 32, in __init__
    super().__init__(process_obj)
  File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/multiprocessing/popen_spawn_posix.py", line 62, in _launch
    f.write(fp.getbuffer())
KeyboardInterrupt
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/erdao/Documents/Qwen3-VL/qwen-vl-finetune/qwenvl/train/train_qwen.py", line 206, in <module>
[rank0]:     train(attn_implementation="flash_attention_2")
[rank0]:   File "/home/erdao/Documents/Qwen3-VL/qwen-vl-finetune/qwenvl/train/train_qwen.py", line 195, in train
[rank0]:     trainer.train()
[rank0]:   File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/transformers/trainer.py", line 2325, in train
[rank0]:     return inner_training_loop(
[rank0]:   File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/transformers/trainer.py", line 2618, in _inner_training_loop
[rank0]:     batch_samples, num_items_in_batch = self.get_batch_samples(epoch_iterator, num_batches, args.device)
[rank0]:   File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/transformers/trainer.py", line 5654, in get_batch_samples
[rank0]:     batch_samples.append(next(epoch_iterator))
[rank0]:   File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/accelerate/data_loader.py", line 563, in __iter__
[rank0]:     dataloader_iter = self.base_dataloader.__iter__()
[rank0]:   File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 491, in __iter__
[rank0]:     return self._get_iterator()
[rank0]:   File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 422, in _get_iterator
[rank0]:     return _MultiProcessingDataLoaderIter(self)
[rank0]:   File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1146, in __init__
[rank0]:     w.start()
[rank0]:   File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/multiprocessing/process.py", line 121, in start
[rank0]:     self._popen = self._Popen(self)
[rank0]:   File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/multiprocessing/context.py", line 224, in _Popen
[rank0]:     return _default_context.get_context().Process._Popen(process_obj)
[rank0]:   File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/multiprocessing/context.py", line 288, in _Popen
[rank0]:     return Popen(process_obj)
[rank0]:   File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/multiprocessing/popen_spawn_posix.py", line 32, in __init__
[rank0]:     super().__init__(process_obj)
[rank0]:   File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
[rank0]:     self._launch(process_obj)
[rank0]:   File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/multiprocessing/popen_spawn_posix.py", line 62, in _launch
[rank0]:     f.write(fp.getbuffer())
[rank0]: KeyboardInterrupt
