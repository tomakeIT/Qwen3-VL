  0%|            | 0/2000 [00:00<?, ?it/s]/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
                                                         
{'loss': 3.3341, 'grad_norm': 36.00718307495117, 'learning_rate': 0.0, 'epoch': 1.0}
{'loss': 3.3341, 'grad_norm': 35.73025131225586, 'learning_rate': 3.333333333333333e-09, 'epoch': 2.0}
{'loss': 3.3391, 'grad_norm': 35.3465461730957, 'learning_rate': 6.666666666666666e-09, 'epoch': 3.0}
{'loss': 3.3446, 'grad_norm': 35.96390914916992, 'learning_rate': 1e-08, 'epoch': 4.0}
{'loss': 3.3026, 'grad_norm': 35.72726058959961, 'learning_rate': 1.3333333333333332e-08, 'epoch': 5.0}
{'loss': 3.3743, 'grad_norm': 35.95563507080078, 'learning_rate': 1.6666666666666664e-08, 'epoch': 6.0}
{'loss': 3.307, 'grad_norm': 35.085235595703125, 'learning_rate': 2e-08, 'epoch': 7.0}
{'loss': 3.3397, 'grad_norm': 35.92469787597656, 'learning_rate': 2.3333333333333334e-08, 'epoch': 8.0}
{'loss': 3.3782, 'grad_norm': 36.150665283203125, 'learning_rate': 2.6666666666666664e-08, 'epoch': 9.0}
{'loss': 3.3369, 'grad_norm': 35.599491119384766, 'learning_rate': 3e-08, 'epoch': 10.0}
{'loss': 3.3063, 'grad_norm': 35.679893493652344, 'learning_rate': 3.333333333333333e-08, 'epoch': 11.0}
{'loss': 3.3367, 'grad_norm': 36.314937591552734, 'learning_rate': 3.6666666666666664e-08, 'epoch': 12.0}
{'loss': 3.3255, 'grad_norm': 35.78866195678711, 'learning_rate': 4e-08, 'epoch': 13.0}
{'loss': 3.3635, 'grad_norm': 35.552650451660156, 'learning_rate': 4.333333333333333e-08, 'epoch': 14.0}
{'loss': 3.2971, 'grad_norm': 35.85511779785156, 'learning_rate': 4.666666666666667e-08, 'epoch': 15.0}
{'loss': 3.2873, 'grad_norm': 35.42900466918945, 'learning_rate': 5e-08, 'epoch': 16.0}
{'loss': 3.3133, 'grad_norm': 35.97384262084961, 'learning_rate': 5.333333333333333e-08, 'epoch': 17.0}
{'loss': 3.3235, 'grad_norm': 35.60795593261719, 'learning_rate': 5.6666666666666665e-08, 'epoch': 18.0}
{'loss': 3.3112, 'grad_norm': 35.89402389526367, 'learning_rate': 6e-08, 'epoch': 19.0}
{'loss': 3.3007, 'grad_norm': 35.89168167114258, 'learning_rate': 6.333333333333333e-08, 'epoch': 20.0}
{'loss': 3.3074, 'grad_norm': 35.836631774902344, 'learning_rate': 6.666666666666665e-08, 'epoch': 21.0}
{'loss': 3.3024, 'grad_norm': 35.739173889160156, 'learning_rate': 6.999999999999999e-08, 'epoch': 22.0}
{'loss': 3.3277, 'grad_norm': 35.92862319946289, 'learning_rate': 7.333333333333333e-08, 'epoch': 23.0}
{'loss': 3.2965, 'grad_norm': 36.15835952758789, 'learning_rate': 7.666666666666666e-08, 'epoch': 24.0}
{'loss': 3.3191, 'grad_norm': 36.1014518737793, 'learning_rate': 8e-08, 'epoch': 25.0}
{'loss': 3.3297, 'grad_norm': 36.09077072143555, 'learning_rate': 8.333333333333334e-08, 'epoch': 26.0}
{'loss': 3.2661, 'grad_norm': 35.62508773803711, 'learning_rate': 8.666666666666666e-08, 'epoch': 27.0}
{'loss': 3.2847, 'grad_norm': 35.44893264770508, 'learning_rate': 9e-08, 'epoch': 28.0}
{'loss': 3.2504, 'grad_norm': 35.476070404052734, 'learning_rate': 9.333333333333334e-08, 'epoch': 29.0}
{'loss': 3.2908, 'grad_norm': 35.81092071533203, 'learning_rate': 9.666666666666666e-08, 'epoch': 30.0}
{'loss': 3.3211, 'grad_norm': 35.40523910522461, 'learning_rate': 1e-07, 'epoch': 31.0}
{'loss': 3.2677, 'grad_norm': 35.854637145996094, 'learning_rate': 1.0333333333333335e-07, 'epoch': 32.0}
{'loss': 3.2807, 'grad_norm': 36.091617584228516, 'learning_rate': 1.0666666666666666e-07, 'epoch': 33.0}
{'loss': 3.2793, 'grad_norm': 35.897705078125, 'learning_rate': 1.1e-07, 'epoch': 34.0}
{'loss': 3.3046, 'grad_norm': 35.791748046875, 'learning_rate': 1.1333333333333333e-07, 'epoch': 35.0}
  File "/home/erdao/Documents/Qwen3-VL/qwen-vl-finetune/qwenvl/train/train_qwen.py", line 206, in <module>
    train(attn_implementation="flash_attention_2")
  File "/home/erdao/Documents/Qwen3-VL/qwen-vl-finetune/qwenvl/train/train_qwen.py", line 195, in train
    trainer.train()
  File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
  File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/transformers/trainer.py", line 2618, in _inner_training_loop
    batch_samples, num_items_in_batch = self.get_batch_samples(epoch_iterator, num_batches, args.device)
  File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/transformers/trainer.py", line 5654, in get_batch_samples
    batch_samples.append(next(epoch_iterator))
  File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/accelerate/data_loader.py", line 563, in __iter__
    dataloader_iter = self.base_dataloader.__iter__()
  File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 491, in __iter__
    return self._get_iterator()
  File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 422, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1146, in __init__
    w.start()
  File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/multiprocessing/context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/multiprocessing/context.py", line 288, in _Popen
    return Popen(process_obj)
  File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/multiprocessing/popen_spawn_posix.py", line 32, in __init__
    super().__init__(process_obj)
  File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/multiprocessing/popen_spawn_posix.py", line 62, in _launch
    f.write(fp.getbuffer())
KeyboardInterrupt
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/erdao/Documents/Qwen3-VL/qwen-vl-finetune/qwenvl/train/train_qwen.py", line 206, in <module>
[rank0]:     train(attn_implementation="flash_attention_2")
[rank0]:   File "/home/erdao/Documents/Qwen3-VL/qwen-vl-finetune/qwenvl/train/train_qwen.py", line 195, in train
[rank0]:     trainer.train()
[rank0]:   File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/transformers/trainer.py", line 2325, in train
[rank0]:     return inner_training_loop(
[rank0]:   File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/transformers/trainer.py", line 2618, in _inner_training_loop
[rank0]:     batch_samples, num_items_in_batch = self.get_batch_samples(epoch_iterator, num_batches, args.device)
[rank0]:   File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/transformers/trainer.py", line 5654, in get_batch_samples
[rank0]:     batch_samples.append(next(epoch_iterator))
[rank0]:   File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/accelerate/data_loader.py", line 563, in __iter__
[rank0]:     dataloader_iter = self.base_dataloader.__iter__()
[rank0]:   File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 491, in __iter__
[rank0]:     return self._get_iterator()
[rank0]:   File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 422, in _get_iterator
[rank0]:     return _MultiProcessingDataLoaderIter(self)
[rank0]:   File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1146, in __init__
[rank0]:     w.start()
[rank0]:   File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/multiprocessing/process.py", line 121, in start
[rank0]:     self._popen = self._Popen(self)
[rank0]:   File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/multiprocessing/context.py", line 224, in _Popen
[rank0]:     return _default_context.get_context().Process._Popen(process_obj)
[rank0]:   File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/multiprocessing/context.py", line 288, in _Popen
[rank0]:     return Popen(process_obj)
[rank0]:   File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/multiprocessing/popen_spawn_posix.py", line 32, in __init__
[rank0]:     super().__init__(process_obj)
[rank0]:   File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
[rank0]:     self._launch(process_obj)
[rank0]:   File "/home/erdao/miniconda3/envs/qwen-train/lib/python3.10/multiprocessing/popen_spawn_posix.py", line 62, in _launch
[rank0]:     f.write(fp.getbuffer())
[rank0]: KeyboardInterrupt
