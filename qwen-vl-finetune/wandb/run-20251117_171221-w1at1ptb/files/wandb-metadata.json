{
  "os": "Linux-6.14.0-35-generic-x86_64-with-glibc2.39",
  "python": "CPython 3.10.19",
  "startedAt": "2025-11-17T22:12:21.603263Z",
  "args": [
    "--deepspeed",
    "./scripts/zero2.json",
    "--model_name_or_path",
    "/home/erdao/Documents/Qwen3-VL/models/Qwen-VL-2B-Instruct",
    "--dataset_use",
    "demo",
    "--data_flatten",
    "True",
    "--tune_mm_vision",
    "False",
    "--tune_mm_mlp",
    "True",
    "--tune_mm_llm",
    "True",
    "--bf16",
    "--lora_enable",
    "True",
    "--output_dir",
    "./output",
    "--num_train_epochs",
    "2000",
    "--per_device_train_batch_size",
    "8",
    "--per_device_eval_batch_size",
    "16",
    "--gradient_accumulation_steps",
    "1",
    "--max_pixels",
    "50176",
    "--min_pixels",
    "784",
    "--eval_strategy",
    "no",
    "--save_strategy",
    "steps",
    "--save_steps",
    "1000",
    "--save_total_limit",
    "1",
    "--learning_rate",
    "2e-7",
    "--weight_decay",
    "0",
    "--warmup_ratio",
    "0.03",
    "--max_grad_norm",
    "1",
    "--lr_scheduler_type",
    "cosine",
    "--logging_steps",
    "1",
    "--model_max_length",
    "2048",
    "--gradient_checkpointing",
    "True",
    "--dataloader_num_workers",
    "8",
    "--run_name",
    "qwen2vl-1gpu-test",
    "--report_to",
    "wandb"
  ],
  "program": "/home/erdao/Documents/Qwen3-VL/qwen-vl-finetune/qwenvl/train/train_qwen.py",
  "codePath": "qwen-vl-finetune/qwenvl/train/train_qwen.py",
  "codePathLocal": "qwenvl/train/train_qwen.py",
  "git": {
    "remote": "https://github.com/tomakeIT/Qwen3-VL.git",
    "commit": "54014bdc0db161182dac3c417028253ade457bf5"
  },
  "email": "charlienijialeng@icloud.com",
  "root": "/home/erdao/Documents/Qwen3-VL/qwen-vl-finetune",
  "host": "erdao-NUC",
  "executable": "/home/erdao/miniconda3/envs/qwen-train/bin/python3.10",
  "cpu_count": 24,
  "cpu_count_logical": 32,
  "gpu": "NVIDIA GeForce RTX 3090",
  "gpu_count": 1,
  "disk": {
    "/": {
      "total": "982240026624",
      "used": "337324568576"
    }
  },
  "memory": {
    "total": "66966302720"
  },
  "gpu_nvidia": [
    {
      "name": "NVIDIA GeForce RTX 3090",
      "memoryTotal": "25769803776",
      "cudaCores": 10496,
      "architecture": "Ampere",
      "uuid": "GPU-541b982d-22df-8e52-52c2-c259b34982c4"
    }
  ],
  "cudaVersion": "13.0",
  "writerId": "lg8e18ejbqedfdrhblf5pc3d6macxpqw"
}